{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "    roc_auc_score, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.read_csv('classification.csv')\n",
    "scores = pd.read_csv('scores.csv')\n",
    "\n",
    "true = classification['true']\n",
    "pred = classification['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 34, 59, 64])"
      ]
     },
     "execution_count": 196,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# confusion matrix\n",
    "np.concatenate([x for x in confusion_matrix(true, pred, labels=[1,0]).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true positive rate \n",
    "# recall\n",
    "# TPR\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "\n",
    "# true negative rate\n",
    "# SPC\n",
    "specitivity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# PPV\n",
    "precision = true_positive / (true_positive + false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.535\nprecision 0.558441558442\nrecall 0.421568627451\nf1 0.480446927374\n"
     ]
    }
   ],
   "source": [
    "# Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "accuracy = accuracy_score(true, pred)\n",
    "# Precision (точность) — sklearn.metrics.precision_score\n",
    "precision = precision_score(true, pred)\n",
    "# Recall (полнота) — sklearn.metrics.recall_score\n",
    "recall = recall_score(true, pred)\n",
    "# F-мера — sklearn.metrics.f1_score\n",
    "f1 = f1_score(true, pred)\n",
    "\n",
    "print 'accuracy', accuracy\n",
    "print 'precision', precision\n",
    "print 'recall', recall\n",
    "print 'f1', f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logreg 0.524909963986\nscore_svm 0.531012404962\nscore_knn 0.485494197679\nscore_tree 0.517256902761\n"
     ]
    }
   ],
   "source": [
    "# Посчитайте основные метрики качества классификатора:\n",
    "score_logreg = scores['score_logreg']\n",
    "score_svm    = scores['score_svm']\n",
    "score_knn    = scores['score_knn']\n",
    "score_tree   = scores['score_tree']\n",
    "print 'score_logreg', roc_auc_score(true, score_logreg)\n",
    "print 'score_svm', roc_auc_score(true, score_svm)\n",
    "print 'score_knn', roc_auc_score(true, score_knn)\n",
    "print 'score_tree', roc_auc_score(true, score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает три массива: precision, recall, thresholds\n",
    "score_logreg_prc = precision_recall_curve(true, score_logreg)\n",
    "score_svm_prc    = precision_recall_curve(true, score_svm)\n",
    "score_knn_prc    = precision_recall_curve(true, score_knn)\n",
    "score_tree_prc   = precision_recall_curve(true, score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "score_logreg_recall = score_logreg_prc[1]\n",
    "score_svm_recall    = score_svm_prc[1]\n",
    "score_knn_recall    = score_knn_prc[1]\n",
    "score_tree_recall   = score_tree_prc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall > 0.7\n",
    "score_logreg_recall_70 = np.where(score_logreg_recall > 0.7)[0]\n",
    "score_svm_recall_70    = np.where(score_svm_recall > 0.7)[0]\n",
    "score_knn_recall_70    = np.where(score_knn_recall > 0.7)[0]\n",
    "score_tree_recall_70   = np.where(score_tree_recall > 0.7)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logreg_max_precision 0.548148148148\nscore_svm_max_precision 0.553846153846\nscore_knn_max_precision 0.530386740331\nscore_tree_max_precision 0.515151515152\n"
     ]
    }
   ],
   "source": [
    "print 'score_logreg_max_precision', max(score_svm_prc[0][score_logreg_recall_70])\n",
    "print 'score_svm_max_precision',    max(score_svm_prc[0][score_svm_recall_70])\n",
    "print 'score_knn_max_precision',    max(score_svm_prc[0][score_knn_recall_70])\n",
    "print 'score_tree_max_precision',   max(score_svm_prc[0][score_tree_recall_70])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}